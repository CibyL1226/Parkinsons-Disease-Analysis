{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIJ0aRq_miZE","executionInfo":{"status":"ok","timestamp":1729887813916,"user_tz":420,"elapsed":58246,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}},"outputId":"31fc344b-be21-4af8-ebf8-07af1f222c80"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"iih-TCZPjRkD","executionInfo":{"status":"ok","timestamp":1729887824164,"user_tz":420,"elapsed":10252,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.cluster import KMeans, DBSCAN\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.multiclass import OneVsRestClassifier\n","import seaborn as sns\n","from sklearn.neighbors import KNeighborsClassifier\n","import matplotlib.patches as mpatches\n","from scipy.stats import mode\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import GridSearchCV\n","from xgboost import XGBClassifier\n","import tensorflow as tf\n","from sklearn import tree\n","from sklearn.metrics import accuracy_score, f1_score, recall_score\n","from sklearn.preprocessing import label_binarize\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.calibration import calibration_curve\n","from sklearn.linear_model import SGDClassifier\n","from mpl_toolkits.mplot3d import Axes3D\n","from statsmodels.tsa.arima.model import ARIMA\n","# Set pandas to display all columns\n","# pd.set_option('display.max_columns', None)"]},{"cell_type":"markdown","source":["**Download Datasets**"],"metadata":{"id":"g8Qlt4NfbSvm"}},{"cell_type":"code","source":["# Voice measuement Dataset\n","# df1 = pd.read_csv(\"/parkinsons.data\")\n","\n","# Read your five mjf dataframes\n","mjf1 = pd.read_csv(\"/content/drive/MyDrive/Mile Stone 2/Dataset/MDS/MDS-UPDRS_Part_I_Patient_Questionnaire_11Sep2024.csv\")\n","mjf2 = pd.read_csv(\"/content/drive/MyDrive/Mile Stone 2/Dataset/MDS/MDS_UPDRS_Part_II__Patient_Questionnaire_11Sep2024.csv\")\n","mjf3 = pd.read_csv(\"/content/drive/MyDrive/Mile Stone 2/Dataset/MDS/MDS-UPDRS_Part_III_11Sep2024.csv\")\n","\n","# Demographic and status\n","demo = pd.read_csv(\"/content/drive/MyDrive/Mile Stone 2/Dataset/Demographic/Demographics_17Sep2024.csv\")\n","status = pd.read_csv(\"/content/drive/MyDrive/Mile Stone 2/Dataset/Demographic/Participant_Status_17Sep2024.csv\")\n","\n","# Datadict\n","data_dict = pd.read_csv(\"/content/drive/MyDrive/Mile Stone 2/Dataset/MDS/ppmi_data_dictionary_merge.csv\")"],"metadata":{"id":"EU7kNYnyphs6","executionInfo":{"status":"error","timestamp":1729887824756,"user_tz":420,"elapsed":614,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}},"colab":{"base_uri":"https://localhost:8080/","height":356},"outputId":"3a6781e1-588e-401a-d05e-d8e8f1ce595e"},"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Mile Stone 2/Dataset/MDS/MDS-UPDRS_Part_I_Patient_Questionnaire_11Sep2024.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-c0c73845efe2>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read your five mjf dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmjf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Mile Stone 2/Dataset/MDS/MDS-UPDRS_Part_I_Patient_Questionnaire_11Sep2024.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmjf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Mile Stone 2/Dataset/MDS/MDS_UPDRS_Part_II__Patient_Questionnaire_11Sep2024.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmjf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Mile Stone 2/Dataset/MDS/MDS-UPDRS_Part_III_11Sep2024.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Mile Stone 2/Dataset/MDS/MDS-UPDRS_Part_I_Patient_Questionnaire_11Sep2024.csv'"]}]},{"cell_type":"code","source":["# Concatenate the dataframes along the column axis (axis=1)\n","concatenated_df = pd.concat([mjf1, mjf2, mjf3], axis=1)\n","\n","# Remove duplicate 'PATNO', 'REC_ID', 'EVENT_ID' columns if they exist\n","concatenated_df = concatenated_df.loc[:,~concatenated_df.columns.duplicated()]\n","\n","# List of columns to retain\n","columns_to_keep = ['PATNO', 'REC_ID', 'EVENT_ID',\n","                   'NP1SLPN', 'NP1SLPD', 'NP1PAIN', 'NP1URIN', 'NP1CNST', 'NP1LTHD', 'NP1FATG',\n","                   'NP2SPCH', 'NP2SALV', 'NP2SWAL', 'NP2EAT', 'NP2DRES', 'NP2HYGN', 'NP2HWRT',\n","                   'NP2HOBB', 'NP2TURN', 'NP2TRMR', 'NP2RISE', 'NP2WALK', 'NP2FREZ',\n","                   'NP3SPCH', 'NP3FACXP', 'NP3RIGN', 'NP3RIGRU', 'NP3RIGLU', 'NP3RIGRL', 'NP3RIGLL',\n","                   'NP3FTAPR', 'NP3FTAPL', 'NP3HMOVR', 'NP3HMOVL', 'NP3PRSPR', 'NP3PRSPL', 'NP3TTAPR',\n","                   'NP3TTAPL', 'NP3LGAGR', 'NP3LGAGL', 'NP3RISNG', 'NP3GAIT', 'NP3FRZGT', 'NP3PSTBL',\n","                   'NP3POSTR', 'NP3BRADY', 'NP3PTRMR', 'NP3PTRML', 'NP3KTRMR', 'NP3KTRML',\n","                   'NP3RTARU', 'NP3RTALU', 'NP3RTARL', 'NP3RTALL', 'NP3RTALJ', 'NP3RTCON']\n","\n","# Filter the dataframe to include only the specified columns\n","final_df = concatenated_df[columns_to_keep]"],"metadata":{"id":"zLRT561Li6MK","executionInfo":{"status":"aborted","timestamp":1729887824758,"user_tz":420,"elapsed":31,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_df = final_df.dropna()\n","\n","# Define the list of event IDs you want to keep (up to V10)\n","valid_event_ids = [\"BL\", \"V04\", \"V06\", \"V10\"]\n","\n","# Filter the dataframe to keep only rows where 'EVENT_ID' is in the valid_event_ids\n","filtered_until_v10_df = final_df[final_df['EVENT_ID'].isin(valid_event_ids)]\n","\n","# Save the filtered dataframe to a new CSV file\n","filtered_until_v10_df.to_csv(\"filtered_parkinson_patients_until_v10.csv\", index=False)\n","\n","# Confirm the file is saved\n","print(\"File saved as 'filtered_parkinson_patients_until_v10.csv'\")"],"metadata":{"id":"akv3goHInppu","executionInfo":{"status":"aborted","timestamp":1729887824758,"user_tz":420,"elapsed":30,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_cleaned = filtered_until_v10_df[(filtered_until_v10_df != 101).all(axis=1)]"],"metadata":{"id":"emTsqpuiYFZm","executionInfo":{"status":"aborted","timestamp":1729887824758,"user_tz":420,"elapsed":30,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# First, select the columns of interest from demo and status\n","demo_selected = demo[['PATNO', 'SEX']]\n","status_selected = status[['PATNO', 'COHORT_DEFINITION']]\n","\n","# Step 1: Merge demo with df_cleaned on PATNO\n","merged_df = pd.merge(df_cleaned, demo_selected, on='PATNO', how='inner')\n","\n","# Step 2: Merge the result with status on PATNO\n","final_df = pd.merge(merged_df, status_selected, on='PATNO', how='inner')\n","\n","# Display the final dataframe\n","final_df.head()\n","\n","# Save the final dataframe\n","final_df.to_csv(\"merged_parkinson_data.csv\", index=False)\n","\n","# Confirm the file is saved\n","print(\"File saved as 'merged_parkinson_data.csv'\")"],"metadata":{"id":"SjWVAvYHWaO4","executionInfo":{"status":"aborted","timestamp":1729887824759,"user_tz":420,"elapsed":30,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 1: Create a dictionary to map ITM_NAME to DSCR. Rename the columns to make them more legible\n","column_mapping = dict(zip(data_dict['ITM_NAME'], data_dict['DSCR']))\n","\n","# Step 2: Rename columns in final_df based on the mapping\n","final_df_renamed = final_df.rename(columns=column_mapping)\n","final_df_renamed.to_csv(\"final_df_renamed.csv\", index=False)"],"metadata":{"id":"ghsDTGBJYlzb","executionInfo":{"status":"aborted","timestamp":1729887824759,"user_tz":420,"elapsed":27,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = final_df_renamed\n","\n","categories = {\n","    'Rigidity': ['3.3a Rigidity - Neck', '3.3b Rigidity - RUE', '3.3c Rigidity - LUE',\n","                 '3.3d Rigidity - RLE', '3.3e Rigidity - LLE'],\n","    'Tremor': ['3.15a Postural tremor - Right Hand', '3.15b Postural tremor - Left hand',\n","               '3.16a Kinetic tremor - Right hand', '3.16b Kinetic tremor - Left hand',\n","               '3.17a Rest tremor amplitude - RUE', '3.17b Rest tremor amplitude - LUE',\n","               '3.17c Rest tremor amplitude - RLE', '3.17d Rest tremor amplitude - LLE',\n","               '3.17e Rest tremor amplitude - Lip/jaw'],\n","    'Motor Function': ['3.4a Finger Tapping Right Hand', '3.4b Finger Tapping Left Hand',\n","                       '3.5a Hand movements - Right Hand', '3.5b Hand movements - Left Hand',\n","                       '3.6a Pronation-Supination - Right Hand', '3.6b Pronation-Supination - Left Hand',\n","                       '3.7a Toe tapping - Right foot', '3.7b Toe tapping - Left foot',\n","                       '3.8a Leg agility - Right leg', '3.8b Leg agility - Left leg'],\n","    'Posture and Gait': ['3.9 Arising from chair', '3.10 Gait', '3.11 Freezing of gait',\n","                         '3.12 Postural stability', '3.13 Posture'],\n","    'Non-Motor Symptoms': ['DAYTIME SLEEPINESS', 'PAIN AND OTHER SENSATIONS', 'URINARY PROBLEMS',\n","                           'CONSTIPATION PROBLEMS', 'LIGHTHEADEDNESS ON STANDING', 'FATIGUE',\n","                           'SPEECH', 'SALIVA + DROOLING', 'CHEWING AND SWALLOWING', 'EATING TASKS',\n","                           'DRESSING', 'HYGIENE', 'HANDWRITING', 'DOING HOBBIES AND OTHER ACTIVITIES',\n","                           'TURNING IN BED']\n","}\n","\n","# Create new columns for the sum values of each category\n","for category, symptoms_list in categories.items():\n","    df[category + ' Sum'] = df[symptoms_list].sum(axis=1)\n","\n","for category, symptoms_list in categories.items():\n","    df[category + ' Mean'] = df[symptoms_list].mean(axis=1)\n","\n","df_sum = df[['Participant ID','Visit ID','Decoded Value for COHORT',\n","             'Rigidity Mean', 'Tremor Mean', 'Motor Function Mean', 'Posture and Gait Mean', 'Non-Motor Symptoms Mean']]\n","df_sum = df[df[\"Decoded Value for COHORT\"] != \"SWEDD\"]\n","output_path = r\"D:\\Downloads\\sum_df.csv\"\n","df_sum.to_csv(output_path, index=False)\n","\n","df_sum = df_sum.drop_duplicates(subset='Participant ID', keep='last').reset_index(drop = True)\n","df_sum.columns"],"metadata":{"id":"XFLnpclw2tMd","executionInfo":{"status":"aborted","timestamp":1729887824759,"user_tz":420,"elapsed":27,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_model = df_sum.drop(columns = ['3.3a Rigidity - Neck', '3.3b Rigidity - RUE', '3.3c Rigidity - LUE',\n","                 '3.3d Rigidity - RLE', '3.3e Rigidity - LLE', '3.15a Postural tremor - Right Hand', '3.15b Postural tremor - Left hand',\n","               '3.16a Kinetic tremor - Right hand', '3.16b Kinetic tremor - Left hand',\n","               '3.17a Rest tremor amplitude - RUE', '3.17b Rest tremor amplitude - LUE',\n","               '3.17c Rest tremor amplitude - RLE', '3.17d Rest tremor amplitude - LLE',\n","               '3.17e Rest tremor amplitude - Lip/jaw', '3.4a Finger Tapping Right Hand', '3.4b Finger Tapping Left Hand',\n","                       '3.5a Hand movements - Right Hand', '3.5b Hand movements - Left Hand',\n","                       '3.6a Pronation-Supination - Right Hand', '3.6b Pronation-Supination - Left Hand',\n","                       '3.7a Toe tapping - Right foot', '3.7b Toe tapping - Left foot',\n","                       '3.8a Leg agility - Right leg', '3.8b Leg agility - Left leg', '3.9 Arising from chair', '3.10 Gait', '3.11 Freezing of gait',\n","                         '3.12 Postural stability', '3.13 Posture', 'DAYTIME SLEEPINESS', 'PAIN AND OTHER SENSATIONS', 'URINARY PROBLEMS',\n","                           'CONSTIPATION PROBLEMS', 'LIGHTHEADEDNESS ON STANDING', 'FATIGUE',\n","                           'SPEECH', 'SALIVA + DROOLING', 'CHEWING AND SWALLOWING', 'EATING TASKS',\n","                           'DRESSING', 'HYGIENE', 'HANDWRITING', 'DOING HOBBIES AND OTHER ACTIVITIES',\n","                           'TURNING IN BED'])"],"metadata":{"id":"JpV6aMedfkIo","executionInfo":{"status":"aborted","timestamp":1729887824759,"user_tz":420,"elapsed":27,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_model['Decoded Value for COHORT'].value_counts()"],"metadata":{"id":"Dy_fCmOegoKd","executionInfo":{"status":"aborted","timestamp":1729887824759,"user_tz":420,"elapsed":26,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# Step 1: Preprocessing the data\n","# Select only numeric columns for PCA\n","numeric_df = df_model.select_dtypes(include=['float64', 'int64'])\n","# Remove identifier columns ()\n","numeric_df = numeric_df.drop(columns=['Participant ID','Sex of participant at birth'], errors='ignore')\n","\n","# Handle missing values by filling them (you can choose to drop rows/columns with missing data)\n","numeric_df = numeric_df.fillna(numeric_df.mean())\n","# Standardize the data\n","scaler = StandardScaler()\n","scaled_data = scaler.fit_transform(numeric_df)\n","\n","# Step 2: Perform PCA\n","pca = PCA(n_components=0.95)  # Retain 95% of variance\n","pca_components = pca.fit_transform(scaled_data)\n","\n","# Step 3: Visualize the explained variance\n","plt.figure(figsize=(10, 7))\n","plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, alpha=0.5, align='center')\n","plt.ylabel('Explained Variance Ratio')\n","plt.xlabel('Principal Components')\n","plt.title('PCA Explained Variance')\n","plt.show()\n","\n","# Step 4: Show feature contributions to the principal components\n","# Loadings: contributions of each original feature to the principal components\n","loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(pca.n_components_)], index=numeric_df.columns)\n","\n","# Show the loadings for the first few principal components\n","loadings"],"metadata":{"id":"qbVvLo68mhsh","executionInfo":{"status":"aborted","timestamp":1729887824760,"user_tz":420,"elapsed":26,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install umap-learn"],"metadata":{"id":"YX6sEUNPUyMo","executionInfo":{"status":"aborted","timestamp":1729887824838,"user_tz":420,"elapsed":104,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import umap\n","# import seaborn as sns\n","\n","# # Create the UMAP reducer\n","# reducer = umap.UMAP(n_components=2)\n","\n","# # Fit and transform your data (X is your dataset)\n","# X_umap = reducer.fit_transform(scaled_data)\n","\n","# plt.figure(figsize=(8, 6))\n","# sns.scatterplot(x=X_umap[:, 0], y=X_umap[:, 1], s=50, alpha=0.7, color=\"blue\")\n","# plt.title(\"UMAP Projection (2D)\")\n","# plt.xlabel(\"UMAP 1\")\n","# plt.ylabel(\"UMAP 2\")\n","# plt.show()\n","\n","\n"],"metadata":{"id":"OWe3SNJPJ14L","executionInfo":{"status":"aborted","timestamp":1729887824838,"user_tz":420,"elapsed":103,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#according to the chart 95% of the variance in the data was represented by the first 4 principal components\n","\n","# Use the first 3 principal components for clustering\n","pca_6_components = pca_components[:, :4]\n","\n","# Step 1: Apply K-means clustering\n","kmeans = KMeans(n_clusters=3 , random_state=42)\n","kmeans.fit(pca_6_components)\n","\n","# Step 2: Add the cluster labels to the dataset\n","df_model['cluster'] = kmeans.labels_\n","\n","# Step 3: Visualize the clustering (PCA components)\n","plt.figure(figsize=(10, 7))\n","plt.scatter(pca_6_components[:, 0], pca_6_components[:, 1], c=kmeans.labels_, cmap='viridis')\n","plt.title('K-means Clustering on PCA-transformed Data')\n","plt.xlabel('PCA Component 1')\n","plt.ylabel('PCA Component 2')\n","plt.colorbar()\n","plt.show()"],"metadata":{"id":"jhGis0dYybHu","executionInfo":{"status":"aborted","timestamp":1729887824854,"user_tz":420,"elapsed":119,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_model"],"metadata":{"id":"Hz-0EtqNCvF9","executionInfo":{"status":"aborted","timestamp":1729887824904,"user_tz":420,"elapsed":169,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**DecisionTree**"],"metadata":{"id":"H-1xjbt7Rkgg"}},{"cell_type":"code","source":["# Check if the columns exist before dropping them and handle missing values\n","columns_to_drop = [\"Participant ID\", \"Visit ID\", \"Record ID\"]\n","\n","# Drop the columns if they exist, and drop any rows with missing values\n","df_model2 = df_model.drop(columns=[col for col in columns_to_drop if col in df_sum.columns]).dropna()\n","# Separate features (X) and target (y)\n","X_filtered = df_model2.drop(columns=[\"Decoded Value for COHORT\"])\n","y_filtered = df_model2[\"Decoded Value for COHORT\"]\n","label_encoder = LabelEncoder()\n","# Re-encode the target variable\n","y_filtered_encoded = label_encoder.fit_transform(y_filtered)\n","\n","# Split the filtered data into training and testing sets\n","X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n","    X_filtered, y_filtered_encoded, test_size=0.2, random_state=42\n",")\n","\n","# Train the decision tree model with the filtered data\n","decision_tree_adjusted_sum = DecisionTreeClassifier(random_state=42, max_depth=5)\n","decision_tree_adjusted_sum.fit(X_train_filtered, y_train_filtered)\n","\n","\n","# Adjusting the decision tree visualization to improve readability by reducing font size and controlling layout\n","plt.figure(figsize=(50, 20))\n","tree.plot_tree(\n","    decision_tree_adjusted_sum,\n","    feature_names=X_filtered.columns,\n","    class_names=label_encoder.classes_,\n","    filled=True,\n","    fontsize=10,  # Smaller font size for readability\n","    proportion=True,  # Scale boxes based on samples in each node\n",")\n","plt.title(\"Decision Tree for Parkinson's Disease Dataset\")\n","plt.show()"],"metadata":{"id":"KB9_wj8XAg3j","executionInfo":{"status":"aborted","timestamp":1729887824904,"user_tz":420,"elapsed":169,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Make predictions on the test set\n","y_pred_filtered = decision_tree_adjusted_sum.predict(X_test_filtered)\n","\n","# Calculate accuracy, F1 score, and recall\n","accuracy = accuracy_score(y_test_filtered, y_pred_filtered)\n","f1 = f1_score(y_test_filtered, y_pred_filtered, average='weighted')\n","recall = recall_score(y_test_filtered, y_pred_filtered, average='weighted')\n","\n","# Print the results\n","print(f'Accuracy: {accuracy}')\n","print(f'F1 Score (weighted): {f1}')\n","print(f'Recall (weighted): {recall}')"],"metadata":{"id":"uy-oL0mmBOpv","executionInfo":{"status":"aborted","timestamp":1729887824904,"user_tz":420,"elapsed":158,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Logistic Regression"],"metadata":{"id":"GTNMVl-ZRvXC"}},{"cell_type":"code","source":["df_model.columns"],"metadata":{"id":"2SUbmwg4hgeP","executionInfo":{"status":"aborted","timestamp":1729887824905,"user_tz":420,"elapsed":69501,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df = pd.read_csv('/content/drive/MyDrive/Mile Stone 2/Dataset/MDS/sum_df.csv')\n","# Proper selection of multiple columns\n","df = df_model[['Participant ID', 'Record ID', 'Visit ID', 'Sex of participant at birth',\n","         'Decoded Value for COHORT',\n","               'Rigidity Mean', 'Tremor Mean', 'Motor Function Mean', 'Posture and Gait Mean', 'Non-Motor Symptoms Mean']]\n","df"],"metadata":{"id":"pYljF8mQBSA2","executionInfo":{"status":"aborted","timestamp":1729887824905,"user_tz":420,"elapsed":69493,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data in to 80/20 train test set\n","X = df.drop(columns=['Participant ID', 'Decoded Value for COHORT','Visit ID','Record ID'])\n","y = df['Decoded Value for COHORT']\n","\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=42,stratify=y)\n","y_train = y_train.replace({'Healthy Control': 0, 'Parkinson\\'s Disease': 1, 'Prodromal': 0})\n","y_test = y_test.replace({'Healthy Control': 0, 'Parkinson\\'s Disease': 1, 'Prodromal': 0})\n","print(f\"Training set size: {X_train.shape[0]}\")\n","print(f\"Test set size: {X_test.shape[0]}\")"],"metadata":{"id":"LDqiWpL-OURm","executionInfo":{"status":"aborted","timestamp":1729887824905,"user_tz":420,"elapsed":69489,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Identify continuous columns\n","continuous_cols = X_train.select_dtypes(include=['float64','int64']).columns\n","# Create preprocessor for continuous columns\n","preprocessor = ColumnTransformer(\n","    transformers = [\n","        ('num',Pipeline(steps =[\n","            ('imputer',SimpleImputer(strategy='mean')),\n","            ('scaler',MinMaxScaler())\n","        ]),continuous_cols)\n","    ],remainder = 'passthrough'\n",")\n","preprocessor"],"metadata":{"id":"mYCks20wO4It","executionInfo":{"status":"aborted","timestamp":1729887824905,"user_tz":420,"elapsed":69483,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_reg = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('classifier', LogisticRegression(random_state=42))\n","])\n","# Perform cross-validation to compare AUC\n","log_reg_auc = cross_val_score(log_reg, X_train, y_train, cv=5, scoring='roc_auc')\n","print(np.std(log_reg_auc))\n","print(np.mean(log_reg_auc))"],"metadata":{"id":"hRCQyOEC9xCD","executionInfo":{"status":"aborted","timestamp":1729887824905,"user_tz":420,"elapsed":69478,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_predict\n","from sklearn.metrics import precision_score, recall_score\n","\n","y_pred = cross_val_predict(log_reg, X_train, y_train, cv = 5)\n","precision = precision_score(y_train, y_pred)\n","recall = recall_score(y_train, y_pred)\n","\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")"],"metadata":{"id":"c_40KLDqK4Rd","executionInfo":{"status":"aborted","timestamp":1729887824905,"user_tz":420,"elapsed":69473,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Perform cross-validation and store AUC for Logistic Regression\n","log_reg.fit(X_train, y_train)  # Train the Logistic Regression model\n","y_pred_probs_log = log_reg.predict_proba(X_test)[:, 1]  # Get predicted probabilities for ROC and calibration\n","\n","# Calculate AUC for Logistic Regression\n","log_reg_auc = roc_auc_score(y_test, y_pred_probs_log)\n","print(f\"Logistic Regression AUC: {log_reg_auc:.3f}\")\n","\n","# Plot ROC Curve for Logistic Regression\n","fpr_log, tpr_log, _ = roc_curve(y_test, y_pred_probs_log)\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr_log, tpr_log, label=f\"Logistic Regression (AUC = {log_reg_auc:.3f})\")\n","plt.plot([0, 1], [0, 1], \"k--\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve - Logistic Regression\")\n","plt.legend()\n","plt.show()\n","\n","# Plot Calibration Curve for Logistic Regression\n","fraction_of_positives_log, mean_predicted_value_log = calibration_curve(y_test, y_pred_probs_log, n_bins=10)\n","\n","plt.figure(figsize=(8, 6))\n","plt.plot(mean_predicted_value_log, fraction_of_positives_log, \"s-\", label=\"Logistic Regression\")\n","plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n","plt.title(\"Calibration Curve - Logistic Regression\")\n","plt.xlabel(\"Mean Predicted Probability\")\n","plt.ylabel(\"Fraction of Positives\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"YxRmxfs9-Oeg","executionInfo":{"status":"aborted","timestamp":1729887824905,"user_tz":420,"elapsed":69466,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Random Forest"],"metadata":{"id":"ra6fa5XspI-B"}},{"cell_type":"code","source":["rf_clf = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('classifier', RandomForestClassifier(random_state=42))\n","])\n","# Perform cross-validation to compare AUC\n","rf_auc = cross_val_score(rf_clf, X_train, y_train, cv=5, scoring='roc_auc')\n","print(np.std(rf_auc))\n","print(np.mean(rf_auc))"],"metadata":{"id":"6_kbHvSXpBbW","executionInfo":{"status":"aborted","timestamp":1729887824906,"user_tz":420,"elapsed":69463,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = MinMaxScaler()\n","X_scaled = scaler.fit_transform(X_train)\n","\n","best_model = LogisticRegression(random_state = 42)\n","best_model.fit(X_scaled, y_train)\n","\n","coefficients = best_model.coef_[0]\n","feature_names = X.columns\n","\n","# Create a DataFrame to pair features with coefficients\n","importance_df = pd.DataFrame({\n","    'Feature': feature_names,\n","    'Coefficient': coefficients\n","})\n","\n","# Sort by absolute value of the coefficients\n","importance_df['Importance'] = np.abs(importance_df['Coefficient'])\n","importance_df = importance_df.sort_values(by='Importance', ascending=False)\n","\n","# Display the top features\n","print(importance_df)\n","\n","# Plot feature importance\n","plt.figure(figsize=(10, 6))\n","plt.barh(importance_df['Feature'], importance_df['Importance'], color='b')\n","plt.xlabel('Absolute Coefficient Value')\n","plt.title('Feature Importance in Logistic Regression')\n","plt.gca().invert_yaxis()\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"E8JxLgdn7d-U","executionInfo":{"status":"aborted","timestamp":1729887824906,"user_tz":420,"elapsed":69455,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg_values = np.logspace(-4, 4, 10)\n","\n","scores = []\n","\n","for C in reg_values:\n","    lr = LogisticRegression(C = C, random_state = 42)\n","    score = cross_val_score(lr, X_train, y_train, cv=5, scoring='accuracy')\n","    scores.append(score.mean())\n","\n","plt.plot(reg_values, scores)\n","plt.xscale('log')\n","plt.xlabel('Regularization Strength (C)')\n","plt.ylabel('Cross-Validated Accuracy')\n","plt.title('Hyperparameter Sensitivity: Regularization Strength (C)')\n","plt.show()"],"metadata":{"id":"g0iRr6-oDOrW","executionInfo":{"status":"aborted","timestamp":1729887824906,"user_tz":420,"elapsed":69448,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1JD-UfNEMv1I","executionInfo":{"status":"aborted","timestamp":1729887824906,"user_tz":420,"elapsed":69447,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Perform cross-validation and store AUC for Random Forest\n","rf_clf.fit(X_train, y_train)  # Train the Random Forest model\n","y_pred_probs_rf = rf_clf.predict_proba(X_test)[:, 1]  # Get predicted probabilities for ROC and calibration\n","\n","# Calculate AUC for Random Forest\n","rf_auc = roc_auc_score(y_test, y_pred_probs_rf)\n","print(f\"Random Forest AUC: {rf_auc:.3f}\")\n","\n","# Plot ROC Curve for Random Forest\n","fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_probs_rf)\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr_rf, tpr_rf, label=f\"Random Forest (AUC = {rf_auc:.3f})\")\n","plt.plot([0, 1], [0, 1], \"k--\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve - Random Forest\")\n","plt.legend()\n","plt.show()\n","\n","# Plot Calibration Curve for Random Forest\n","fraction_of_positives_rf, mean_predicted_value_rf = calibration_curve(y_test, y_pred_probs_rf, n_bins=10)\n","\n","plt.figure(figsize=(8, 6))\n","plt.plot(mean_predicted_value_rf, fraction_of_positives_rf, \"s-\", label=\"Random Forest\")\n","plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n","plt.title(\"Calibration Curve - Random Forest\")\n","plt.xlabel(\"Mean Predicted Probability\")\n","plt.ylabel(\"Fraction of Positives\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"SKhPhgIppBWN","executionInfo":{"status":"aborted","timestamp":1729887824906,"user_tz":420,"elapsed":69440,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = log_reg if log_reg_auc > rf_auc else rf_clf\n","# Fit the best model to the training data\n","best_model.fit(X_train, y_train)\n","\n","# Predict probabilities on the test set\n","y_pred_prob = best_model.predict_proba(X_test)[:, 1]\n","\n","# Calculate and report AUC on the test set\n","test_auc = roc_auc_score(y_test, y_pred_prob)\n","print(f\"Test AUC: {test_auc}\")"],"metadata":{"id":"96fRQmnSpBOP","executionInfo":{"status":"aborted","timestamp":1729887824909,"user_tz":420,"elapsed":69440,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8, 6))\n","plt.hist(y_pred_prob, bins=20, edgecolor='k', alpha=0.7)\n","plt.xlabel('Predicted Probability of Failure')\n","plt.ylabel('Frequency')\n","plt.title('Distribution of Predicted Probabilities')\n","plt.show()"],"metadata":{"id":"AqjqzOvOpUb3","executionInfo":{"status":"aborted","timestamp":1729887824909,"user_tz":420,"elapsed":69434,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Identify predicted probability threshold to identify the top 20% highest risk patients"],"metadata":{"id":"vleniWDMe1Fz"}},{"cell_type":"code","source":["threshold = np.percentile(y_pred_prob, 80)\n","print(f\"Probability threshold for top 20% highest risk patients: {threshold}\")\n","\n","# Identify students in the top 20% of risk based on this threshold\n","high_risk_patients = X_test[y_pred_prob >= threshold]\n","print(f\"Number of high-risk patients: {len(high_risk_patients)}\")"],"metadata":{"id":"XwpYqcX8euxr","executionInfo":{"status":"aborted","timestamp":1729887824909,"user_tz":420,"elapsed":69429,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualization\n","ROC Curve:\n","Show how well the model distinguishes between high-risk and low-risk patients for conversion to Parkinson’s.\n","\n","Calibration Curve:\n","Demonstrate how reliable the model’s predicted probabilities are for actual patient outcomes.\n","\n","Distribution of Probabilities:\n","Use a histogram to show the range of predicted risk probabilities among patients, illustrating the threshold that marks the top 20%."],"metadata":{"id":"i5jCF056pZdT"}},{"cell_type":"markdown","source":[" ## Key Finding\n","Highlight the most important findings:\n","\n","Probability Threshold: The model determined that patients with a predicted risk probability of 0.78 or higher are in the top 20% of those at highest risk for developing Parkinson's disease.\n","\n","High-Risk Group: Out of the patients in the test set, 275 patients were identified as being in this high-risk category, meaning they are most likely to convert to Parkinson’s disease based on their current symptoms."],"metadata":{"id":"E8yJkgM6pZQs"}},{"cell_type":"markdown","source":["## Implication\n","By focusing on the top 20% of at-risk patients, healthcare providers can prioritize these individuals for more frequent monitoring, early interventions, or tailored treatment plans. Identifying high-risk patients early can help slow disease progression or improve patient outcomes.\n"],"metadata":{"id":"m0KXsOakpY9j"}},{"cell_type":"code","source":["y_train"],"metadata":{"id":"S1dcsz8y2SKT","executionInfo":{"status":"aborted","timestamp":1729887824910,"user_tz":420,"elapsed":69423,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Neural Network"],"metadata":{"id":"HjqQIFURC6P4"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","\n","# Step 4: Normalize the data using StandardScaler\n","scaler = MinMaxScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Step 5: Define the neural network\n","model = Sequential()\n","\n","# Input layer\n","model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n","\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(64, activation='relu'))\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n","\n","test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n","print(f\"Test Accuracy: {test_acc:.4f}\")"],"metadata":{"id":"tal31io1C8xc","executionInfo":{"status":"aborted","timestamp":1729887824910,"user_tz":420,"elapsed":69419,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Time Series analysis"],"metadata":{"id":"-ldyIU-4pY19"}},{"cell_type":"code","source":["visit_mapping = {\n","    'BL': 1,\n","    'V02': 2,\n","    'V04': 4,\n","    'V06': 6,\n","    'V08': 8,\n","    'V10': 10\n","}\n","\n","# Apply this mapping to the \"Visit ID\" column\n","df['Visit Number'] = df['Visit ID'].map(visit_mapping)\n","\n","# Sorting data by Participant ID and Visit Number to ensure correct time sequence\n","df = df.sort_values(by=['Participant ID', 'Visit Number'])"],"metadata":{"id":"PoBQvWg5UYbs","executionInfo":{"status":"aborted","timestamp":1729887825206,"user_tz":420,"elapsed":17,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Selecting relevant columns for the analysis\n","symptoms_columns = ['Tremor Mean', 'Rigidity Mean', 'Motor Function Mean',\n","                    'Posture and Gait Mean', 'Non-Motor Symptoms Mean']\n","\n","# Grouping the data by Visit Number to calculate the mean of symptoms across visits\n","symptoms_progression = df.groupby('Visit Number')[symptoms_columns].mean()\n","\n","# Function to forecast future visits using ARIMA model and plot results\n","def forecast_symptom(symptom_name, steps=6):\n","    # Selecting the symptom data and dropping null values\n","    symptom_data = symptoms_progression[symptom_name].dropna()\n","\n","    # Define the ARIMA model (p=1, d=1, q=1) as an initial guess\n","    arima_model = ARIMA(symptom_data, order=(1, 1, 1))\n","    arima_result = arima_model.fit()\n","\n","    # Forecast for the next `steps` periods (including V11 to V18)\n","    forecast = arima_result.forecast(steps=steps)\n","\n","    # Plotting the historical data and forecasted data\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(symptoms_progression.index, symptom_data, label=f'{symptom_name} (Historical)', marker='o')\n","    plt.plot(range(symptoms_progression.index[-1] + 1, symptoms_progression.index[-1] + 1 + steps),\n","             forecast, label=f'{symptom_name} (Forecast)', linestyle='--', marker='x')\n","    plt.title(f'Forecast of {symptom_name} Progression')\n","    plt.xlabel('Visit Number')\n","    plt.ylabel(f'{symptom_name} Value')\n","    plt.legend(loc='best')\n","    plt.grid(True)\n","    plt.show()\n","\n","# Apply the forecasting function to \"Tremor Mean\"\n","forecast_symptom('Tremor Mean')\n","\n","# Apply the forecasting function to \"Rigidity Mean\"\n","forecast_symptom('Rigidity Mean')\n","\n","# Apply the forecasting function to \"Motor Function Mean\"\n","forecast_symptom('Motor Function Mean')"],"metadata":{"id":"Tt4rKi-FSTTH","executionInfo":{"status":"aborted","timestamp":1729887825206,"user_tz":420,"elapsed":17,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Gradient Descent and Multiple Regression"],"metadata":{"id":"-JFSObvX04yC"}},{"cell_type":"code","source":["# First step labeling Parkinson or Healthy Control\n","# Creating the 'Parkinson' column based on the \"Decoded Value for COHORT\"\n","df['Parkinson'] = df['Decoded Value for COHORT'].apply(lambda x: 1 if x == \"Parkinson's Disease\" else 0)\n","\n","# Checking the distribution of the new Parkinson column\n","df['Parkinson'].value_counts()\n","X = df[['Rigidity Mean','Tremor Mean','Motor Function Mean','Posture and Gait Mean','Non-Motor Symptoms Mean']].dropna()\n","y = df['Parkinson'].dropna()"],"metadata":{"id":"2uHtbVYW1CNZ","executionInfo":{"status":"aborted","timestamp":1729887825207,"user_tz":420,"elapsed":18,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardizing the features for better performance in gradient descent\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Using SGDClassifier with logistic loss function to perform gradient descent\n","sgd_classifier = SGDClassifier(loss='log_loss', max_iter=1000, learning_rate='optimal', random_state=42)\n","sgd_classifier.fit(X_train_scaled, y_train)\n","\n","# Getting the weights (coefficients) learned by the model\n","sgd_weights = sgd_classifier.coef_\n","\n","# Displaying the resulting weights\n","sgd_weights, sgd_classifier.intercept_"],"metadata":{"id":"BNQUJlmW1J9d","executionInfo":{"status":"aborted","timestamp":1729887825207,"user_tz":420,"elapsed":18,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sigmoid(z):\n","    \"\"\"\n","    Compute the sigmoid of z.\n","\n","    Parameters:\n","    z: A scalar or numpy array of any size.\n","\n","    Returns:\n","    The sigmoid of z.\n","    \"\"\"\n","    return 1 / (1 + np.exp(-z))"],"metadata":{"id":"Jx2xQffY-dhb","executionInfo":{"status":"aborted","timestamp":1729887825207,"user_tz":420,"elapsed":17,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cost_function(w1, w2, X1, X2, y):\n","    m = len(y)\n","    predictions = sigmoid(w1 * X1 + w2 * X2)\n","    cost = -(1/m) * np.sum(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n","    return cost\n","\n","# Creating a mesh grid for two variables (weights w1 and w2)\n","w1_vals = np.linspace(-1, 1, 100)\n","w2_vals = np.linspace(-1, 1, 100)\n","w1_vals, w2_vals = np.meshgrid(w1_vals, w2_vals)\n","\n","# Assume we're using \"Rigidity Sum\" and \"Tremor Sum\" for the 3D visualization\n","X1 = X['Rigidity Mean'].values\n","X2 = X['Tremor Mean'].values\n","y_values = y.values\n","\n","# Calculate the cost for each combination of w1 and w2\n","Z = np.array([cost_function(w1, w2, X1, X2, y_values) for w1, w2 in zip(np.ravel(w1_vals), np.ravel(w2_vals))])\n","Z = Z.reshape(w1_vals.shape)\n","\n","# Gradient descent path for two weights (example)\n","path_w1 = np.array([0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0])\n","path_w2 = np.array([0.5, 0.45, 0.35, 0.25, 0.15, 0.1, 0.05])\n","path_cost = np.array([cost_function(w1, w2, X1, X2, y_values) for w1, w2 in zip(path_w1, path_w2)])\n","\n","# Plotting the 3D surface for the cost function\n","fig = plt.figure(figsize=(10, 8))\n","ax = fig.add_subplot(111, projection='3d')\n","ax.plot_surface(w1_vals, w2_vals, Z, cmap='viridis', alpha=0.6)\n","ax.plot(path_w1, path_w2, path_cost, color='r', marker='o', label='Gradient Descent Path')\n","\n","# Labels and titles\n","ax.set_title('Gradient Descent Path on Cost Surface')\n","ax.set_xlabel('Weight 1 (Rigidity Mean)')\n","ax.set_ylabel('Weight 2 (Tremor Mean)')\n","ax.set_zlabel('Cost')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"6xGRGLj81Ojm","executionInfo":{"status":"aborted","timestamp":1729887825207,"user_tz":420,"elapsed":13,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_weights = np.array([ 0.10789418,  0.03946231, -0.1268167 , -0.06324631,  0.77659627])\n","intercept = -0.08475943  # Intercept (bias term)\n","\n","# Features (X) - the same features used in gradient descent\n","X_features = X[['Rigidity Mean', 'Tremor Mean', 'Motor Function Mean', 'Posture and Gait Mean', 'Non-Motor Symptoms Mean']].values\n","\n","# Linear regression prediction: y_pred = X * weights + intercept\n","y_pred = np.dot(X_features, gradient_weights) + intercept\n","\n","# Since this is a logistic regression-like model, we can apply the sigmoid function to interpret the predictions as probabilities\n","y_pred_probabilities = sigmoid(y_pred)\n","\n","# Thresholding to classify as Parkinson's (1) or not (0), based on probability >= 0.5\n","y_pred_class = (y_pred_probabilities >= 0.5).astype(int)\n","\n","# Displaying a few predicted classes\n","y_pred_class[:10], y_pred_probabilities[:10]"],"metadata":{"id":"MxISr9m31TOQ","executionInfo":{"status":"aborted","timestamp":1729887825207,"user_tz":420,"elapsed":12,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate the Model"],"metadata":{"id":"U9xRpX1U1W0z"}},{"cell_type":"code","source":["# Ground truth (actual labels)\n","y_true = y.values\n","\n","# Confusion Matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_class)\n","\n","# ROC Curve\n","fpr, tpr, thresholds = roc_curve(y_true, y_pred_probabilities)\n","roc_auc = roc_auc_score(y_true, y_pred_probabilities)\n","\n","# Classification Report\n","class_report = classification_report(y_true, y_pred_class)\n","\n"],"metadata":{"id":"CLtwOj5n1bGZ","executionInfo":{"status":"aborted","timestamp":1729887825207,"user_tz":420,"elapsed":12,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert classification report to a dictionary first, then create a DataFrame\n","class_report_dict = classification_report(y_true, y_pred_class, output_dict=True)\n","\n","# Convert the dictionary to a pandas DataFrame\n","class_report_df = pd.DataFrame(class_report_dict).transpose()\n","\n","# Display the DataFrame\n","print(class_report_df)\n","\n","# Visualization : ROC Curve\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr, tpr, color='orange', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n","plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"kPmADvSI1iuJ","executionInfo":{"status":"aborted","timestamp":1729887825208,"user_tz":420,"elapsed":12,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Key Insight\n","The model is much better at detecting Parkinson's diseas(class1)but it struggles to identify true negatives (class 0), leading to poor performance for \"Not Parkinson\" cases.\n","Precision is balanced between the classes, but the low recall for class 0 suggests that the model is highly biased toward predicting Parkinson's disease.\n","An AUC of 0.72 indicates decent discrimination between the two classes."],"metadata":{"id":"uLzBYHVo6FlN"}},{"cell_type":"markdown","source":["## Agglomerative Hierarchical Clustering:\n"],"metadata":{"id":"q3Hiyrlp8ON7"}},{"cell_type":"code","source":["from scipy.cluster.hierarchy import dendrogram, linkage\n","from sklearn.cluster import AgglomerativeClustering\n","\n","\n","X = df[['Rigidity Mean', 'Tremor Mean', 'Motor Function Mean', 'Posture and Gait Mean', 'Non-Motor Symptoms Mean']].dropna()\n","\n","# Step 2: Standardize the Data\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Step 3: Compute the linkage matrix for hierarchical clustering\n","linked = linkage(X_scaled, method='complete')\n","\n","# Step 4: Plot the Dendrogram\n","plt.figure(figsize=(10, 7))\n","dendrogram(linked, truncate_mode='level', p=5, orientation='top', distance_sort='descending', show_leaf_counts=True)\n","plt.title('Hierarchical Clustering Dendrogram')\n","plt.xlabel('Patient Index')\n","plt.ylabel('Distance')\n","plt.show()\n","\n","# Step 5: Perform Agglomerative Clustering\n","cluster = AgglomerativeClustering(n_clusters=4, linkage='single')\n","labels = cluster.fit_predict(X_scaled)\n","\n","# Step 6: Add the cluster labels to the dataset\n","df['Cluster'] = labels\n","\n","# Display first few rows with clusters\n","df.head()"],"metadata":{"id":"FOJsxnhT8i5R","executionInfo":{"status":"aborted","timestamp":1729887825210,"user_tz":420,"elapsed":14,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip install mglearn\n"],"metadata":{"id":"h9iBHEhoXf28","executionInfo":{"status":"aborted","timestamp":1729887825210,"user_tz":420,"elapsed":14,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import mglearn\n","import matplotlib.pyplot as plt\n","\n","mglearn.discrete_scatter(X_scaled[:,0], X_scaled[:, 1], labels)\n","#plt.legend(\"Cluster 0\", \"Cluster 1\", \"Cluster 2\", loc = \"best\")\n","plt.title(\"Agglomerative Hierarchical Clustering Plot (Single Linkage)\")\n","plt.show()"],"metadata":{"id":"3cIZ4j4wWygy","executionInfo":{"status":"aborted","timestamp":1729887825210,"user_tz":420,"elapsed":14,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.cluster import DBSCAN\n","dbscan = DBSCAN()\n","clusters = dbscan.fit_predict(X_scaled)\n","\n","plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c = clusters, cmap = mglearn.cm2, s = 30)\n","plt.title(\"DBSCAN Plot\")"],"metadata":{"id":"Y2nFsn-Ja-sr","executionInfo":{"status":"aborted","timestamp":1729887825218,"user_tz":420,"elapsed":22,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.cluster.hierarchy import fcluster\n","\n","clusters = fcluster(linked, t=60, criterion='distance')\n","\n","#  Filter to include only numeric columns\n","numeric_cols = X\n","\n","# Add the cluster labels to the numeric data\n","numeric_cols['Cluster'] = df['Cluster']\n","\n","# Calculate the mean for each cluster, ignoring non-numeric columns\n","cluster_means = numeric_cols.groupby('Cluster').mean()\n","cluster_means\n"],"metadata":{"id":"wsjuYD52DMlO","executionInfo":{"status":"aborted","timestamp":1729887825218,"user_tz":420,"elapsed":22,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cluster 1:\n","Rigidity Sum: 7.49\n","Tremor Sum: 2.79\n","Motor Function Sum: 19.00\n","Posture and Gait Sum: 9.23\n","Non-Motor Symptoms Sum: 5.09\n","\n","Cluster 2:\n","Rigidity Sum: 3.60\n","Tremor Sum: 1.39\n","Motor Function Sum: 9.33\n","Posture and Gait Sum: 2.04\n","Non-Motor Symptoms Sum: 4.44\n","\n","Cluster 3:\n","Rigidity Sum: 6.39\n","Tremor Sum: 5.65\n","Motor Function Sum: 12.02\n","Posture and Gait Sum: 2.56\n","Non-Motor Symptoms Sum: 6.36\n","\n","Cluster 4:\n","Rigidity Sum: 0.44\n","Tremor Sum: 0.68\n","Motor Function Sum: 1.33\n","Posture and Gait Sum: 0.58\n","Non-Motor Symptoms Sum: 4.59\n","\n","Cluster 5:\n","Rigidity Sum: 1.76\n","Tremor Sum: 1.92\n","Motor Function Sum: 5.03\n","Posture and Gait Sum: 1.17\n","Non-Motor Symptoms Sum: 15.58\n","\n","## Summary of Clusters:\n","Cluster 1: Moderate-to-severe motor dysfunction with notable posture and gait issues.\n","\n","Cluster 2: Mild motor symptoms, with minimal posture and gait impairment.\n","\n","Cluster 3: Severe tremor, moderate motor dysfunction, and higher non-motor symptoms.\n","\n","Cluster 4: Very mild motor symptoms but moderate non-motor symptoms.\n","\n","Cluster 5: Mild motor symptoms but very high non-motor complications."],"metadata":{"id":"D9K7qtwj8igw"}},{"cell_type":"code","source":["# Visualize the distribution of Tremor Sum across clusters\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(x='Cluster', y='Tremor Mean', data=df)\n","plt.title('Distribution of Tremor Sum Across Clusters')\n","plt.show()\n","\n","# Visualize the distribution of Non-Motor Symptoms Sum across clusters\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(x='Cluster', y='Non-Motor Symptoms Mean', data=df)\n","plt.title('Distribution of Non-Motor Symptoms Sum Across Clusters')\n","plt.show()\n","\n","# Visualize the distribution of Non-Motor Symptoms Sum across clusters\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(x='Cluster', y='Rigidity Mean', data=df)\n","plt.title('Distribution of Rigidity Sum Across Clusters')\n","plt.show()\n","\n","# Visualize the distribution of Non-Motor Symptoms Sum across clusters\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(x='Cluster', y='Posture and Gait Mean', data=df)\n","plt.title('Distribution of Posture and Gait Sum Across Clusters')\n","plt.show()\n","\n","# Visualize the distribution of Non-Motor Symptoms Sum across clusters\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(x='Cluster', y='Motor Function Mean', data=df)\n","plt.title('Distribution of Motor Function Sum  Across Clusters')\n","plt.show()"],"metadata":{"id":"jJEwFPgrGGco","executionInfo":{"status":"aborted","timestamp":1729887825218,"user_tz":420,"elapsed":21,"user":{"displayName":"Ciby Lin","userId":"00229977188303964910"}}},"execution_count":null,"outputs":[]}]}
